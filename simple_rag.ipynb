{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 RAG(검색 지원 생성) 시스템\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 코드는 PDF 문서를 처리하고 쿼리하기 위한 기본적인 검색 지원 생성(RAG) 시스템을 구현합니다. 시스템은 문서 콘텐츠를 벡터 저장소로 인코딩하여 관련 정보를 검색할 수 있습니다.\n",
    "\n",
    "## 주요 구성 요소\n",
    "\n",
    "1. PDF 처리 및 텍스트 추출\n",
    "2. 관리 가능한 처리를 위한 텍스트 청크\n",
    "3. FAISS 및 SDS 임베딩을 사용한 벡터 저장소 만들기\n",
    "4. 처리된 문서를 쿼리하기 위한 검색기 설정\n",
    "5. RAG 시스템의 평가\n",
    "\n",
    "## 방법 세부 정보\n",
    "\n",
    "### 문서 전처리\n",
    "\n",
    "1. PyPDFLoader를 사용하여 PDF를 로드합니다.\n",
    "2. 지정된 청크 크기와 겹치는 부분을 사용하여 재귀적 문자 텍스트 분할기를 사용하여 텍스트를 청크로 분할합니다.\n",
    "\n",
    "### 텍스트 정리\n",
    "\n",
    "사용자 지정 함수인 replace\\_t\\_with\\_space를 적용하여 텍스트 청크를 정리합니다. 이는 PDF의 특정 서식 문제를 해결할 가능성이 높습니다.\n",
    "\n",
    "### 벡터 저장소 만들기\n",
    "\n",
    "1. SDS 임베딩을 사용하여 텍스트 청크의 벡터 표현을 만듭니다.\n",
    "2. 효율적인 유사도 검색을 위해 이러한 임베딩으로 FAISS 벡터 저장소를 만듭니다.\n",
    "\n",
    "### 검색기 설정\n",
    "\n",
    "1. 검색기가 주어진 쿼리에 대해 가장 관련된 두 개의 청크를 가져오도록 구성됩니다.\n",
    "\n",
    "### 인코딩 함수\n",
    "\n",
    "`encode_pdf` 함수는 PDF를 로드, 청크화, 정리 및 벡터 저장소로 인코딩하는 전체 프로세스를 캡슐화합니다.\n",
    "\n",
    "## 주요 기능\n",
    "\n",
    "1. 모듈식 설계: 인코딩 프로세스는 재사용이 용이하도록 단일 함수에 캡슐화됩니다.\n",
    "2. 구성 가능한 청크화: 청크 크기와 겹침을 조정할 수 있습니다.\n",
    "3. 효율적인 검색: 빠른 유사도 검색을 위해 FAISS를 사용합니다.\n",
    "4. 평가: RAG 시스템의 성능을 평가하는 기능이 포함되어 있습니다.\n",
    "\n",
    "## 사용법 예제\n",
    "\n",
    "코드에는 \"기후 변화의 주요 원인은 무엇인가요?\"라는 테스트 쿼리가 포함되어 있습니다. 이것은 처리된 문서에서 관련 컨텍스트를 가져오는 데 검색기를 어떻게 사용하는지 보여줍니다.\n",
    "\n",
    "## 평가\n",
    "\n",
    "시스템에는 `evaluate_rag` 함수가 포함되어 있어 검색기의 성능을 평가할 수 있지만 제공되는 코드에서는 특정 메트릭이 자세히 설명되어 있지 않습니다.\n",
    "\n",
    "## 이 접근법의 이점\n",
    "\n",
    "1. 확장성: 청크로 문서를 처리하여 큰 문서를 처리할 수 있습니다.\n",
    "2. 유연성: 청크 크기 및 검색된 결과 수를 쉽게 조정할 수 있습니다.\n",
    "3. 효율성: 고차원 공간에서 빠른 유사도 검색을 위해 FAISS를 활용합니다.\n",
    "4. 고급 NLP와의 통합: 최첨단 텍스트 표현을 위해 SDS 임베딩을 사용합니다.\n",
    "\n",
    "## 결론\n",
    "\n",
    "이 단순한 RAG 시스템은 보다 복잡한 정보 검색 및 질문 응답 시스템을 구축하기 위한 견고한 기반을 제공합니다. 문서 콘텐츠를 검색 가능한 벡터 저장소에 인코딩함으로써 쿼리에 대한 응답으로 관련 정보의 효율적인 검색을 가능하게 합니다. 이 접근 방식은 특히 대형 문서 또는 문서 컬렉션 내에서 특정 정보에 빠르게 액세스해야 하는 애플리케이션에 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU sentence_transformers langchain_community text_generation fitz PyMuPDF faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path since we work with notebooks\n",
    "from helper_functions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (List)\n",
    "\n",
    "import requests\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "class CustomEmbedding(Embeddings):\n",
    "    def __init__(self):\n",
    "        self.embed_url = 'http://sds-embed.serving.70-220-152-1.sslip.io/v1/models/embed:predict'\n",
    "\n",
    "    def call_embed(self, url, texts):\n",
    "        data = {\n",
    "            \"instances\": texts\n",
    "        }\n",
    "        response = requests.post(url=url, json=data)\n",
    "        result = response.json()\n",
    "        return result['predictions']\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        주어진 텍스트를 임베딩하여 벡터로 반환 합니다.\n",
    "        \"\"\"\n",
    "        embed_list = self.call_embed(url=self.embed_url, texts=texts)\n",
    "        return embed_list\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed query text.\"\"\"\n",
    "\n",
    "        embed_list = self.call_embed(url=self.embed_url, texts=[text])\n",
    "        return embed_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using SDS embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = CustomEmbedding()\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Understanding Climate Change  \n",
      "Chapter 1: Introduction to Climate Change  \n",
      "Climate change refers to significant, long -term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past cent ury, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change.  \n",
      "Historical Context  \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and  human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "\n",
      "\n",
      "Context 2:\n",
      "driven by human activities, particularly the emission of greenhou se gases.  \n",
      "Chapter 2: Causes of Climate Change  \n",
      "Greenhouse Gases  \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate.  \n",
      "Fossil Fuels  \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today.  \n",
      "Coal\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "show_context(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
